{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a699eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import (train_test_split, KFold, StratifiedKFold, GridSearchCV)\n",
    "from models import (get_RF, get_DT, get_knn, get_SVC, get_GBC, get_MLP, run_classifier)\n",
    "from helper_functions import (k_fold_cv, hr,\\\n",
    "     get_sampler, plot_confusion_matrices, plot_roc)\n",
    "import pickle\n",
    "from sklearn.feature_selection import mutual_info_classif, GenericUnivariateSelect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fc79802",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/heart_cleveland_upload.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1ef22bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_data = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "395b9ecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>condition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>54.542088</td>\n",
       "      <td>0.676768</td>\n",
       "      <td>2.158249</td>\n",
       "      <td>131.693603</td>\n",
       "      <td>247.350168</td>\n",
       "      <td>0.144781</td>\n",
       "      <td>0.996633</td>\n",
       "      <td>149.599327</td>\n",
       "      <td>0.326599</td>\n",
       "      <td>1.055556</td>\n",
       "      <td>0.602694</td>\n",
       "      <td>0.676768</td>\n",
       "      <td>0.835017</td>\n",
       "      <td>0.461279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.049736</td>\n",
       "      <td>0.468500</td>\n",
       "      <td>0.964859</td>\n",
       "      <td>17.762806</td>\n",
       "      <td>51.997583</td>\n",
       "      <td>0.352474</td>\n",
       "      <td>0.994914</td>\n",
       "      <td>22.941562</td>\n",
       "      <td>0.469761</td>\n",
       "      <td>1.166123</td>\n",
       "      <td>0.618187</td>\n",
       "      <td>0.938965</td>\n",
       "      <td>0.956690</td>\n",
       "      <td>0.499340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>133.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>56.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>243.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>276.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>564.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age         sex          cp    trestbps        chol         fbs  \\\n",
       "count  297.000000  297.000000  297.000000  297.000000  297.000000  297.000000   \n",
       "mean    54.542088    0.676768    2.158249  131.693603  247.350168    0.144781   \n",
       "std      9.049736    0.468500    0.964859   17.762806   51.997583    0.352474   \n",
       "min     29.000000    0.000000    0.000000   94.000000  126.000000    0.000000   \n",
       "25%     48.000000    0.000000    2.000000  120.000000  211.000000    0.000000   \n",
       "50%     56.000000    1.000000    2.000000  130.000000  243.000000    0.000000   \n",
       "75%     61.000000    1.000000    3.000000  140.000000  276.000000    0.000000   \n",
       "max     77.000000    1.000000    3.000000  200.000000  564.000000    1.000000   \n",
       "\n",
       "          restecg     thalach       exang     oldpeak       slope          ca  \\\n",
       "count  297.000000  297.000000  297.000000  297.000000  297.000000  297.000000   \n",
       "mean     0.996633  149.599327    0.326599    1.055556    0.602694    0.676768   \n",
       "std      0.994914   22.941562    0.469761    1.166123    0.618187    0.938965   \n",
       "min      0.000000   71.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000  133.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      1.000000  153.000000    0.000000    0.800000    1.000000    0.000000   \n",
       "75%      2.000000  166.000000    1.000000    1.600000    1.000000    1.000000   \n",
       "max      2.000000  202.000000    1.000000    6.200000    2.000000    3.000000   \n",
       "\n",
       "             thal   condition  \n",
       "count  297.000000  297.000000  \n",
       "mean     0.835017    0.461279  \n",
       "std      0.956690    0.499340  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    0.000000  \n",
       "50%      0.000000    0.000000  \n",
       "75%      2.000000    1.000000  \n",
       "max      2.000000    1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97e3fab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 297 entries, 0 to 296\n",
      "Data columns (total 14 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   age        297 non-null    int64  \n",
      " 1   sex        297 non-null    int64  \n",
      " 2   cp         297 non-null    int64  \n",
      " 3   trestbps   297 non-null    int64  \n",
      " 4   chol       297 non-null    int64  \n",
      " 5   fbs        297 non-null    int64  \n",
      " 6   restecg    297 non-null    int64  \n",
      " 7   thalach    297 non-null    int64  \n",
      " 8   exang      297 non-null    int64  \n",
      " 9   oldpeak    297 non-null    float64\n",
      " 10  slope      297 non-null    int64  \n",
      " 11  ca         297 non-null    int64  \n",
      " 12  thal       297 non-null    int64  \n",
      " 13  condition  297 non-null    int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 32.6 KB\n"
     ]
    }
   ],
   "source": [
    "heart_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f691b065",
   "metadata": {},
   "source": [
    "That means there are no Null values in this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ec7572a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate Input and Target variables\n",
    "heart_X = heart_data.drop(columns=\"condition\", axis=1)\n",
    "heart_y = heart_data['condition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad333881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.092399</td>\n",
       "      <td>0.110471</td>\n",
       "      <td>0.290476</td>\n",
       "      <td>0.202644</td>\n",
       "      <td>0.132062</td>\n",
       "      <td>0.149917</td>\n",
       "      <td>-0.394563</td>\n",
       "      <td>0.096489</td>\n",
       "      <td>0.197123</td>\n",
       "      <td>0.159405</td>\n",
       "      <td>0.362210</td>\n",
       "      <td>0.120795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>-0.092399</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.008908</td>\n",
       "      <td>-0.066340</td>\n",
       "      <td>-0.198089</td>\n",
       "      <td>0.038850</td>\n",
       "      <td>0.033897</td>\n",
       "      <td>-0.060496</td>\n",
       "      <td>0.143581</td>\n",
       "      <td>0.106567</td>\n",
       "      <td>0.033345</td>\n",
       "      <td>0.091925</td>\n",
       "      <td>0.370556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cp</th>\n",
       "      <td>0.110471</td>\n",
       "      <td>0.008908</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.036980</td>\n",
       "      <td>0.072088</td>\n",
       "      <td>-0.057663</td>\n",
       "      <td>0.063905</td>\n",
       "      <td>-0.339308</td>\n",
       "      <td>0.377525</td>\n",
       "      <td>0.203244</td>\n",
       "      <td>0.151079</td>\n",
       "      <td>0.235644</td>\n",
       "      <td>0.266275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trestbps</th>\n",
       "      <td>0.290476</td>\n",
       "      <td>-0.066340</td>\n",
       "      <td>-0.036980</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.131536</td>\n",
       "      <td>0.180860</td>\n",
       "      <td>0.149242</td>\n",
       "      <td>-0.049108</td>\n",
       "      <td>0.066691</td>\n",
       "      <td>0.191243</td>\n",
       "      <td>0.121172</td>\n",
       "      <td>0.097954</td>\n",
       "      <td>0.130612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chol</th>\n",
       "      <td>0.202644</td>\n",
       "      <td>-0.198089</td>\n",
       "      <td>0.072088</td>\n",
       "      <td>0.131536</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.012708</td>\n",
       "      <td>0.165046</td>\n",
       "      <td>-0.000075</td>\n",
       "      <td>0.059339</td>\n",
       "      <td>0.038596</td>\n",
       "      <td>-0.009215</td>\n",
       "      <td>0.115945</td>\n",
       "      <td>0.023441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fbs</th>\n",
       "      <td>0.132062</td>\n",
       "      <td>0.038850</td>\n",
       "      <td>-0.057663</td>\n",
       "      <td>0.180860</td>\n",
       "      <td>0.012708</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.068831</td>\n",
       "      <td>-0.007842</td>\n",
       "      <td>-0.000893</td>\n",
       "      <td>0.008311</td>\n",
       "      <td>0.047819</td>\n",
       "      <td>0.152086</td>\n",
       "      <td>0.051038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>restecg</th>\n",
       "      <td>0.149917</td>\n",
       "      <td>0.033897</td>\n",
       "      <td>0.063905</td>\n",
       "      <td>0.149242</td>\n",
       "      <td>0.165046</td>\n",
       "      <td>0.068831</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.072290</td>\n",
       "      <td>0.081874</td>\n",
       "      <td>0.113726</td>\n",
       "      <td>0.135141</td>\n",
       "      <td>0.129021</td>\n",
       "      <td>0.013612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thalach</th>\n",
       "      <td>-0.394563</td>\n",
       "      <td>-0.060496</td>\n",
       "      <td>-0.339308</td>\n",
       "      <td>-0.049108</td>\n",
       "      <td>-0.000075</td>\n",
       "      <td>-0.007842</td>\n",
       "      <td>-0.072290</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.384368</td>\n",
       "      <td>-0.347640</td>\n",
       "      <td>-0.389307</td>\n",
       "      <td>-0.268727</td>\n",
       "      <td>-0.258386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exang</th>\n",
       "      <td>0.096489</td>\n",
       "      <td>0.143581</td>\n",
       "      <td>0.377525</td>\n",
       "      <td>0.066691</td>\n",
       "      <td>0.059339</td>\n",
       "      <td>-0.000893</td>\n",
       "      <td>0.081874</td>\n",
       "      <td>-0.384368</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.289310</td>\n",
       "      <td>0.250572</td>\n",
       "      <td>0.148232</td>\n",
       "      <td>0.323268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oldpeak</th>\n",
       "      <td>0.197123</td>\n",
       "      <td>0.106567</td>\n",
       "      <td>0.203244</td>\n",
       "      <td>0.191243</td>\n",
       "      <td>0.038596</td>\n",
       "      <td>0.008311</td>\n",
       "      <td>0.113726</td>\n",
       "      <td>-0.347640</td>\n",
       "      <td>0.289310</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.579037</td>\n",
       "      <td>0.294452</td>\n",
       "      <td>0.336809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slope</th>\n",
       "      <td>0.159405</td>\n",
       "      <td>0.033345</td>\n",
       "      <td>0.151079</td>\n",
       "      <td>0.121172</td>\n",
       "      <td>-0.009215</td>\n",
       "      <td>0.047819</td>\n",
       "      <td>0.135141</td>\n",
       "      <td>-0.389307</td>\n",
       "      <td>0.250572</td>\n",
       "      <td>0.579037</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.109761</td>\n",
       "      <td>0.260096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca</th>\n",
       "      <td>0.362210</td>\n",
       "      <td>0.091925</td>\n",
       "      <td>0.235644</td>\n",
       "      <td>0.097954</td>\n",
       "      <td>0.115945</td>\n",
       "      <td>0.152086</td>\n",
       "      <td>0.129021</td>\n",
       "      <td>-0.268727</td>\n",
       "      <td>0.148232</td>\n",
       "      <td>0.294452</td>\n",
       "      <td>0.109761</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.248825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thal</th>\n",
       "      <td>0.120795</td>\n",
       "      <td>0.370556</td>\n",
       "      <td>0.266275</td>\n",
       "      <td>0.130612</td>\n",
       "      <td>0.023441</td>\n",
       "      <td>0.051038</td>\n",
       "      <td>0.013612</td>\n",
       "      <td>-0.258386</td>\n",
       "      <td>0.323268</td>\n",
       "      <td>0.336809</td>\n",
       "      <td>0.260096</td>\n",
       "      <td>0.248825</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               age       sex        cp  trestbps      chol       fbs  \\\n",
       "age       1.000000 -0.092399  0.110471  0.290476  0.202644  0.132062   \n",
       "sex      -0.092399  1.000000  0.008908 -0.066340 -0.198089  0.038850   \n",
       "cp        0.110471  0.008908  1.000000 -0.036980  0.072088 -0.057663   \n",
       "trestbps  0.290476 -0.066340 -0.036980  1.000000  0.131536  0.180860   \n",
       "chol      0.202644 -0.198089  0.072088  0.131536  1.000000  0.012708   \n",
       "fbs       0.132062  0.038850 -0.057663  0.180860  0.012708  1.000000   \n",
       "restecg   0.149917  0.033897  0.063905  0.149242  0.165046  0.068831   \n",
       "thalach  -0.394563 -0.060496 -0.339308 -0.049108 -0.000075 -0.007842   \n",
       "exang     0.096489  0.143581  0.377525  0.066691  0.059339 -0.000893   \n",
       "oldpeak   0.197123  0.106567  0.203244  0.191243  0.038596  0.008311   \n",
       "slope     0.159405  0.033345  0.151079  0.121172 -0.009215  0.047819   \n",
       "ca        0.362210  0.091925  0.235644  0.097954  0.115945  0.152086   \n",
       "thal      0.120795  0.370556  0.266275  0.130612  0.023441  0.051038   \n",
       "\n",
       "           restecg   thalach     exang   oldpeak     slope        ca      thal  \n",
       "age       0.149917 -0.394563  0.096489  0.197123  0.159405  0.362210  0.120795  \n",
       "sex       0.033897 -0.060496  0.143581  0.106567  0.033345  0.091925  0.370556  \n",
       "cp        0.063905 -0.339308  0.377525  0.203244  0.151079  0.235644  0.266275  \n",
       "trestbps  0.149242 -0.049108  0.066691  0.191243  0.121172  0.097954  0.130612  \n",
       "chol      0.165046 -0.000075  0.059339  0.038596 -0.009215  0.115945  0.023441  \n",
       "fbs       0.068831 -0.007842 -0.000893  0.008311  0.047819  0.152086  0.051038  \n",
       "restecg   1.000000 -0.072290  0.081874  0.113726  0.135141  0.129021  0.013612  \n",
       "thalach  -0.072290  1.000000 -0.384368 -0.347640 -0.389307 -0.268727 -0.258386  \n",
       "exang     0.081874 -0.384368  1.000000  0.289310  0.250572  0.148232  0.323268  \n",
       "oldpeak   0.113726 -0.347640  0.289310  1.000000  0.579037  0.294452  0.336809  \n",
       "slope     0.135141 -0.389307  0.250572  0.579037  1.000000  0.109761  0.260096  \n",
       "ca        0.129021 -0.268727  0.148232  0.294452  0.109761  1.000000  0.248825  \n",
       "thal      0.013612 -0.258386  0.323268  0.336809  0.260096  0.248825  1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_X.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93ba509",
   "metadata": {},
   "source": [
    "From the table above, we can see that no two columns have a high correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9df1cd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer = GenericUnivariateSelect(mutual_info_classif, mode='k_best', param=12)\n",
    "# cols = heart_X.columns\n",
    "# heart_X = transformer.fit_transform(heart_X, heart_y)\n",
    "# print(\"Retained Features: \", transformer.get_feature_names_out(cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54051c30",
   "metadata": {},
   "source": [
    "After experimenting with features, I discovered that Feature Selection is not required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64734a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Standardization to Scale input features\n",
    "from sklearn.preprocessing import (StandardScaler, RobustScaler)\n",
    "\n",
    "std_scaler = StandardScaler()\n",
    "#std_scaler = RobustScaler()\n",
    "\n",
    "heart_X_scaled = std_scaler.fit_transform(heart_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0894f885",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = get_sampler(\"RandomOverSampler\", {\"sampling_strategy\": 1})\n",
    "\n",
    "heart_X_scaled, heart_y = sampler.fit_resample(heart_X_scaled, heart_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03155332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "heart_y.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6c4342",
   "metadata": {},
   "source": [
    "From the histogram, we can see that we have 160 negative examples and 137 positive examples. Thus the data is not imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e92d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_cv(classifier, sampler,  X, y, cv, score_name=\"accuracy\"):\n",
    "    scorers = {\n",
    "        \"accuracy\": accuracy_score,\n",
    "        \"recall\": recall_score,\n",
    "        \"f1\": f1_score,\n",
    "        \"roc_auc\": roc_auc_score,\n",
    "        \"balanced_accuracy\": balanced_accuracy_score\n",
    "    }\n",
    "\n",
    "    scores = []\n",
    "    for train_folds_idx, val_fold_idx in cv.split(X, y):\n",
    "        X_train_fold, y_train_fold = X[train_folds_idx], y[train_folds_idx]\n",
    "        X_val_fold, y_val_fold = X[val_fold_idx], y[val_fold_idx]\n",
    "        if sampler is None:\n",
    "            X_sampled_train, y_sampled_train = X_train_fold, y_train_fold\n",
    "        else:\n",
    "            X_sampled_train, y_sampled_train = sampler.fit_resample(X_train_fold, y_train_fold)\n",
    "        model_obj = classifier.fit(X_sampled_train, y_sampled_train)\n",
    "        score = scorers[score_name](y_val_fold, model_obj.predict(X_val_fold))\n",
    "        scores.append(score)\n",
    "\n",
    "    return np.array(scores).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a00b9a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(heart_X_scaled, heart_y, test_size=0.33, random_state=0, stratify=heart_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7f5962a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constructing parameter dictionary for hyperparameter tuning\n",
    "classifier_param_dict = [\n",
    "    {\n",
    "        \"min_samples_leaf\": [2, 3, 4, 5],\n",
    "        \"criterion\": [\"gini\", \"entropy\", \"log_loss\"],\n",
    "        \"random_state\": [0],\n",
    "        \"min_samples_split\": [2, 3, 5],\n",
    "        \"min_weight_fraction_leaf\": [0.0, 0.1, 0.3, 0.5],\n",
    "        \"max_features\": [\"sqrt\", \"log2\"]\n",
    "        },\n",
    "    {\n",
    "        \"max_depth\": [3, 5, 7],\n",
    "        \"random_state\": [0], \n",
    "        \"criterion\": [\"gini\", \"entropy\", \"log_loss\"],\n",
    "        \"min_weight_fraction_leaf\": [0.0, 0.1, 0.3, 0.5],\n",
    "        \"max_features\": [\"sqrt\", \"log2\"],\n",
    "        \"bootstrap\": [True, False]\n",
    "        },\n",
    "    {\n",
    "        \"kernel\": (\"linear\", \"poly\", \"rbf\"),\n",
    "        \"degree\": [1, 2, 3],\n",
    "        \"random_state\": [0],\n",
    "        \"C\": [0.01, 0.1, 1, 10],\n",
    "        \"probability\": [True],\n",
    "        },\n",
    "    {\n",
    "        \"n_neighbors\": [3, 5, 7],\n",
    "        \"weights\": [\"uniform\", \"distance\"],\n",
    "        \"leaf_size\": [10, 30, 50],\n",
    "        \"p\": [1, 2, 3]\n",
    "        },\n",
    "    {\n",
    "        \"loss\": [\"log_loss\", \"exponential\"],\n",
    "        'criterion': ['friedman_mse', 'squared_error'],\n",
    "        'subsample': [0.1, 0.3, 0.5, 1],\n",
    "        'learning_rate': [0.001, 0.01, 0.1],\n",
    "        'n_estimators': [50, 100, 500],\n",
    "        'max_depth': [3, 5],\n",
    "        \"random_state\": [0],\n",
    "        'max_features': ['sqrt', 'log2']\n",
    "        },\n",
    "    {\n",
    "        \"hidden_layer_sizes\": [(512, 256, 64, 16, 4), (256, 128, 32, 8), (64, 32, 8)],\n",
    "        'activation': ['tanh', 'relu'],\n",
    "        \"random_state\": [0],\n",
    "        'solver': ['sgd', 'adam'],\n",
    "        'alpha': [0.0001, 0.01, 0.1],\n",
    "        'learning_rate': ['constant','adaptive'],\n",
    "        'max_iter': [500]\n",
    "    }\n",
    "]\n",
    "\n",
    "classifiers = [get_DT, get_RF, get_SVC, get_knn, get_GBC, get_MLP]\n",
    "names = [\"DecisionTree\", \"RandomForest\", \"SVC\", \"k-NN\", \"GradientBoostingClassifier\", \"MLP\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cad023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finding out the best Parameters for  DecisionTree\n",
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n",
      "{'criterion': 'gini', 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.1, 'random_state': 0}\n",
      "\n",
      "Finding out the best Parameters for  RandomForest\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      "{'bootstrap': False, 'criterion': 'gini', 'max_depth': 7, 'max_features': 'sqrt', 'min_weight_fraction_leaf': 0.0, 'random_state': 0}\n",
      "\n",
      "Finding out the best Parameters for  SVC\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "{'C': 10, 'degree': 1, 'kernel': 'rbf', 'probability': True, 'random_state': 0}\n",
      "\n",
      "Finding out the best Parameters for  k-NN\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "{'leaf_size': 10, 'n_neighbors': 3, 'p': 2, 'weights': 'distance'}\n",
      "\n",
      "Finding out the best Parameters for  GradientBoostingClassifier\n",
      "Fitting 5 folds for each of 576 candidates, totalling 2880 fits\n",
      "{'criterion': 'friedman_mse', 'learning_rate': 0.1, 'loss': 'log_loss', 'max_depth': 5, 'max_features': 'sqrt', 'n_estimators': 100, 'random_state': 0, 'subsample': 0.1}\n",
      "\n",
      "Finding out the best Parameters for  MLP\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pranshuldobriyal/miniforge3/envs/tf/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/pranshuldobriyal/miniforge3/envs/tf/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/pranshuldobriyal/miniforge3/envs/tf/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/pranshuldobriyal/miniforge3/envs/tf/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/pranshuldobriyal/miniforge3/envs/tf/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/pranshuldobriyal/miniforge3/envs/tf/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/pranshuldobriyal/miniforge3/envs/tf/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/pranshuldobriyal/miniforge3/envs/tf/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/pranshuldobriyal/miniforge3/envs/tf/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/pranshuldobriyal/miniforge3/envs/tf/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/pranshuldobriyal/miniforge3/envs/tf/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/pranshuldobriyal/miniforge3/envs/tf/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/pranshuldobriyal/miniforge3/envs/tf/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/pranshuldobriyal/miniforge3/envs/tf/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/pranshuldobriyal/miniforge3/envs/tf/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/pranshuldobriyal/miniforge3/envs/tf/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/pranshuldobriyal/miniforge3/envs/tf/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/pranshuldobriyal/miniforge3/envs/tf/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/pranshuldobriyal/miniforge3/envs/tf/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/pranshuldobriyal/miniforge3/envs/tf/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/pranshuldobriyal/miniforge3/envs/tf/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/pranshuldobriyal/miniforge3/envs/tf/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/pranshuldobriyal/miniforge3/envs/tf/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/pranshuldobriyal/miniforge3/envs/tf/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/pranshuldobriyal/miniforge3/envs/tf/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/pranshuldobriyal/miniforge3/envs/tf/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/pranshuldobriyal/miniforge3/envs/tf/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/pranshuldobriyal/miniforge3/envs/tf/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/pranshuldobriyal/miniforge3/envs/tf/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/pranshuldobriyal/miniforge3/envs/tf/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/pranshuldobriyal/miniforge3/envs/tf/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/pranshuldobriyal/miniforge3/envs/tf/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pranshuldobriyal/miniforge3/envs/tf/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/pranshuldobriyal/miniforge3/envs/tf/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/pranshuldobriyal/miniforge3/envs/tf/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/pranshuldobriyal/miniforge3/envs/tf/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/pranshuldobriyal/miniforge3/envs/tf/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/pranshuldobriyal/miniforge3/envs/tf/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/pranshuldobriyal/miniforge3/envs/tf/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/pranshuldobriyal/miniforge3/envs/tf/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/pranshuldobriyal/miniforge3/envs/tf/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/pranshuldobriyal/miniforge3/envs/tf/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/pranshuldobriyal/miniforge3/envs/tf/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/pranshuldobriyal/miniforge3/envs/tf/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/pranshuldobriyal/miniforge3/envs/tf/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/pranshuldobriyal/miniforge3/envs/tf/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/pranshuldobriyal/miniforge3/envs/tf/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/pranshuldobriyal/miniforge3/envs/tf/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/pranshuldobriyal/miniforge3/envs/tf/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/pranshuldobriyal/miniforge3/envs/tf/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/pranshuldobriyal/miniforge3/envs/tf/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/pranshuldobriyal/miniforge3/envs/tf/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/pranshuldobriyal/miniforge3/envs/tf/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/pranshuldobriyal/miniforge3/envs/tf/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/pranshuldobriyal/miniforge3/envs/tf/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/pranshuldobriyal/miniforge3/envs/tf/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/pranshuldobriyal/miniforge3/envs/tf/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/pranshuldobriyal/miniforge3/envs/tf/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/pranshuldobriyal/miniforge3/envs/tf/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/pranshuldobriyal/miniforge3/envs/tf/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/pranshuldobriyal/miniforge3/envs/tf/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/pranshuldobriyal/miniforge3/envs/tf/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/pranshuldobriyal/miniforge3/envs/tf/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/pranshuldobriyal/miniforge3/envs/tf/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pranshuldobriyal/miniforge3/envs/tf/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/pranshuldobriyal/miniforge3/envs/tf/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/pranshuldobriyal/miniforge3/envs/tf/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/pranshuldobriyal/miniforge3/envs/tf/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/pranshuldobriyal/miniforge3/envs/tf/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/pranshuldobriyal/miniforge3/envs/tf/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:709: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "/Users/pranshuldobriyal/miniforge3/envs/tf/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/pranshuldobriyal/miniforge3/envs/tf/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#initialise the object for CV sampler\n",
    "# We will use \"Accuracy\" as we are concerned with identifying all the patients with heart-diseases, i.e\n",
    "# We want to identify all True Positives and it is fine to have a few False Positives, but no False Negatives\n",
    "acc= []\n",
    "std = []\n",
    "def run_search():\n",
    "    best_params = {} \n",
    "    for i in range(len(classifiers)):\n",
    "        print(\"\\nFinding out the best Parameters for \", names[i])\n",
    "        # Using GridSearch to get the best combination of parameters\n",
    "        classifier = GridSearchCV(classifiers[i](), classifier_param_dict[i], verbose=1, scoring=\"recall\")\n",
    "        classifier.fit(X_train, y_train)\n",
    "        best_params[names[i]] = classifier.best_params_\n",
    "        print(best_params[names[i]])\n",
    "    with open('best_heart_param_dict.pkl', 'wb') as f:\n",
    "        pickle.dump(best_params, f)\n",
    "\n",
    "# Run the function below to generate a dictionary containing the best parameters for all the classifiers\n",
    "run_search()\n",
    "\n",
    "# Load the best parameters\n",
    "with open('best_heart_param_dict.pkl', 'rb') as f:\n",
    "    best_param = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedd8c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train all classifiers with best parameter values we obtained above\n",
    "for i in range(len(classifiers)):\n",
    "    name = names[i] \n",
    "    classifier = classifiers[i](best_param[names[i]])\n",
    "    met = run_classifier(classifier, X_train, y_train, X_test, y_test, split=False)\n",
    "    plot_confusion_matrices(\"classifying_heart_disease\", met, name)\n",
    "    plot_roc(\"classifying_heart_disease\", met[\"ROC\"], name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7c2763",
   "metadata": {},
   "source": [
    "## Working on the Labor Negotiation Data =>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bf976a",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = [\"duration\", \"wage increase first year\", \"wage increase second year\", \"wage increase third year\",\\\n",
    "           \"cost of living adjustment\", \"working hours\", \"pension\", \"standby pay\", \"shift differential\",\\\n",
    "           \"education allowance\", \"statutory holidays\", \"vacation\", \"longterm disability assistance\",\\\n",
    "           \"contribution to dental plan\", \"bereavement assistance\", \"contribution to health plan\", 'negotiations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1240a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labor_data = pd.read_csv('data/labor-neg.data', header=None, names=headers, na_values = \"?\")\n",
    "train_labor_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a0cbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labor_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9c415c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labor_data = pd.read_csv('data/labor-neg.test', header=None, names=headers, na_values=\"?\")\n",
    "test_labor_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76d84cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labor_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b043620",
   "metadata": {},
   "source": [
    "Let us handle the Missing Values values now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831aa575",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labor_data.negotiations.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d796abfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labor_data.negotiations.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8feec57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f6873ff6",
   "metadata": {},
   "source": [
    "There are no examples with missing values for the target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32707812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For certain columns, it would make sense to fill missing values with the Mean of column\n",
    "col_names = [\"wage increase first year\", \"wage increase second year\", \"wage increase third year\", \"working hours\",\\\n",
    "            \"shift differential\", \"statutory holidays\", \"duration\"]\n",
    "\n",
    "for i in col_names:\n",
    "    train_labor_data[i] = train_labor_data[i].fillna(train_labor_data[i].mean())\n",
    "    test_labor_data[i] = test_labor_data[i].fillna(test_labor_data[i].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a69d93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Certain features have a very high number of missing values, hence it would make sense to drop them\n",
    "col_names = [\"standby pay\", \"cost of living adjustment\", \"pension\"]\n",
    "\n",
    "for i in col_names:\n",
    "    train_labor_data = train_labor_data.drop([i],axis=1)\n",
    "    test_labor_data = test_labor_data.drop([i],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb0c12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labor_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7efab81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling Categorical Missing Values by filling with most frequent element\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "col_names = [\"education allowance\", \"vacation\", \"longterm disability assistance\", \"contribution to dental plan\",\\\n",
    "            \"bereavement assistance\", \"contribution to health plan\"]\n",
    "\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "for i in col_names:\n",
    "    train_labor_data[i] = imputer.fit_transform(np.array(train_labor_data[i]).reshape(-1, 1))\n",
    "    test_labor_data[i] = imputer.fit_transform(np.array(test_labor_data[i]).reshape(-1, 1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309490a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_labor_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c321676f",
   "metadata": {},
   "source": [
    "#### Time to convert Categorical Data into Numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fe3cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "col_names = [\"education allowance\", \"vacation\", \"longterm disability assistance\", \"contribution to dental plan\",\\\n",
    "            \"bereavement assistance\", \"contribution to health plan\"]\n",
    "\n",
    "for i in col_names:\n",
    "    encoded_data = pd.get_dummies(train_labor_data[i], prefix=i)\n",
    "    train_labor_data = pd.concat([train_labor_data, encoded_data], axis = 1)\n",
    "    train_labor_data.drop([i], axis=1, inplace=True)\n",
    "    \n",
    "    encoded_data = pd.get_dummies(test_labor_data[i], prefix=i)\n",
    "    test_labor_data = pd.concat([test_labor_data, encoded_data], axis = 1)\n",
    "    test_labor_data.drop([i], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ab3684",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "train_labor_data[\"negotiations\"] = LabelBinarizer().fit_transform(train_labor_data[\"negotiations\"])\n",
    "test_labor_data[\"negotiations\"] = LabelBinarizer().fit_transform(test_labor_data[\"negotiations\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81390ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labor_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d64756",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labor_data.corr() > 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70308b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into train and test\n",
    "X_train = train_labor_data.drop(columns=\"negotiations\", axis=1)\n",
    "y_train = train_labor_data['negotiations']\n",
    "X_test = test_labor_data.drop(columns=\"negotiations\", axis=1)\n",
    "y_test = test_labor_data[\"negotiations\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33809107",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb146a75",
   "metadata": {},
   "source": [
    "The data is not highly imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ab6657",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Standardization to Scale input features\n",
    "\n",
    "std_scaler = StandardScaler()\n",
    "#std_scaler = RobustScaler()\n",
    "\n",
    "X_train = std_scaler.fit_transform(X_train)\n",
    "X_test = std_scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc9951d",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc= []\n",
    "std = []\n",
    "def run_labor_search():\n",
    "    best_params = {} \n",
    "    for i in range(len(classifiers)):\n",
    "        print(\"\\nFinding out the best Parameters for \", names[i])\n",
    "        # Using GridSearch to get the best combination of parameters\n",
    "        classifier = GridSearchCV(classifiers[i](), classifier_param_dict[i], verbose=1, scoring=\"accuracy\")\n",
    "        classifier.fit(X_train, y_train)\n",
    "        best_params[names[i]] = classifier.best_params_\n",
    "        print(best_params[names[i]])\n",
    "    with open('best_labor_param_dict.pkl', 'wb') as f:\n",
    "        pickle.dump(best_params, f)\n",
    "\n",
    "# Run the function below to generate a dictionary containing the best parameters for all the classifiers\n",
    "run_labor_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d930f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best parameters\n",
    "with open('best_labor_param_dict.pkl', 'rb') as f:\n",
    "    best_param = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60538037",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(classifiers)):\n",
    "    name = names[i] \n",
    "    param = best_param[names[i]]\n",
    "    if name == \"MLP\":\n",
    "        param[\"max_iter\"] = 1000\n",
    "    else:\n",
    "        continue\n",
    "    classifier = classifiers[i](param)\n",
    "\n",
    "    met = run_classifier(classifier, X_train, y_train, X_test, y_test, split=False)\n",
    "    plot_confusion_matrices(\"classifying_labor_neg\", met, name)\n",
    "    plot_roc(\"classifying_labor_neg\", met[\"ROC\"], name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7d86ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
